{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNOtobpfD588kDIu3xwFWs8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sJJqfo4AJK2O"},"outputs":[],"source":["!git clone https://github.com/mapup/MapUp-Data-Assessment-F.git"]},{"cell_type":"code","source":["import pandas as pd\n","\n","file_path = '/content/MapUp-Data-Assessment-F/datasets/dataset-1.csv'\n","\n","df = pd.read_csv(file_path)\n","\n","df.head()"],"metadata":{"id":"P_vm-9JmTIFv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = '/content/MapUp-Data-Assessment-F/templates/python_task_1.py'\n","\n","\n","with open(file_path, 'r') as file:\n","    python_code = file.read()\n","\n","\n","print(python_code)"],"metadata":{"id":"2kbyVh7TLm56"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","def generate_car_matrix(df):\n","    \"\"\"\n","    Creates a DataFrame for id combinations.\n","\n","    Args:\n","        df (pandas.DataFrame)\n","\n","    Returns:\n","        pandas.DataFrame: Matrix generated with 'car' values,\n","                          where 'id_1' and 'id_2' are used as indices and columns respectively.\n","    \"\"\"\n","\n","    car_matrix = df.pivot(index='id_1', columns='id_2', values='car').fillna(0)\n","\n","    return car_matrix\n","\n","def get_type_count(df):\n","    \"\"\"\n","    Categorizes 'car' values into types and returns a dictionary of counts.\n","\n","    Args:\n","        df (pandas.DataFrame)\n","\n","    Returns:\n","        dict: A dictionary with car types as keys and their counts as values.\n","    \"\"\"\n","\n","    df['car_type'] = pd.cut(df['car'], bins=[float('-inf'), 15, 25, float('inf')],\n","                           labels=['low', 'medium', 'high'], right=False)\n","\n","    # Count occurrences of each car_type category\n","    type_counts = df['car_type'].value_counts().to_dict()\n","\n","    # Sort the dictionary alphabetically based on keys\n","    type_counts = dict(sorted(type_counts.items()))\n","\n","    return type_counts\n","\n","def get_bus_indexes(df):\n","    \"\"\"\n","    Returns the indexes where the 'bus' values are greater than twice the mean.\n","\n","    Args:\n","        df (pandas.DataFrame)\n","\n","    Returns:\n","        list: List of indexes where 'bus' values exceed twice the mean.\n","    \"\"\"\n","\n","    bus_indexes = df[df['bus'] > 2 * df['bus'].mean()].index.tolist()\n","\n","\n","    bus_indexes.sort()\n","\n","    return bus_indexes\n","\n","def filter_routes(df):\n","    \"\"\"\n","    Filters and returns routes with average 'truck' values greater than 7.\n","\n","    Args:\n","        df (pandas.DataFrame)\n","\n","    Returns:\n","        list: List of route names with average 'truck' values greater than 7.\n","    \"\"\"\n","\n","    route_averages = df.groupby('route')['truck'].mean()\n","\n","\n","    filtered_routes = route_averages[route_averages > 7].index.tolist()\n","\n","    # Sort the list of route names\n","    filtered_routes.sort()\n","\n","    return filtered_routes\n","\n","def multiply_matrix(matrix):\n","    \"\"\"\n","    Multiplies matrix values with custom conditions.\n","\n","    Args:\n","        matrix (pandas.DataFrame)\n","\n","    Returns:\n","        pandas.DataFrame: Modified matrix with values multiplied based on custom conditions.\n","    \"\"\"\n","\n","    modified_matrix = matrix.applymap(lambda x: x * 0.75 if x > 20 else x * 1.25)\n","\n","    # Round values to 1 decimal place\n","    modified_matrix = modified_matrix.round(1)\n","\n","    return modified_matrix\n","\n","file_path = '/content/MapUp-Data-Assessment-F/datasets/dataset-1.csv'\n","\n","df = pd.read_csv(file_path)\n","\n","car_matrix_result = generate_car_matrix(df)\n","\n","print(\"Resulting Car Matrix:\")\n","print(car_matrix_result)\n","\n","type_count_result = get_type_count(df)\n","\n","# Display the resulting dictionary of car type counts\n","print(\"\\nType Count Dictionary:\")\n","print(type_count_result)\n","\n","bus_indexes_result = get_bus_indexes(df)\n","\n","print(\"\\nBus Indexes Exceeding Twice the Mean:\")\n","print(bus_indexes_result)\n","\n","filtered_routes_result = filter_routes(df)\n","\n","# Display the resulting list of route names with average 'truck' values greater than 7\n","print(\"\\nFiltered Routes with Average 'Truck' > 7:\")\n","print(filtered_routes_result)\n","\n","# Apply the multiply_matrix function to the Car Matrix DataFrame\n","modified_matrix_result = multiply_matrix(car_matrix_result)\n","\n","# Display the resulting modified matrix\n","print(\"\\nModified Car Matrix:\")\n","print(modified_matrix_result)"],"metadata":{"id":"F8Ffv8HXb0kD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","file_path_2 = '/content/MapUp-Data-Assessment-F/datasets/dataset-2.csv'\n","\n","df = pd.read_csv(file_path_2)\n","\n","df.head()"],"metadata":{"id":"ZKp78UUvcj2D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","def time_check(df):\n","    \"\"\"\n","    Use shared dataset-2 to verify the completeness of the data by checking whether the timestamps for each unique (`id`, `id_2`) pair cover a full 24-hour and 7 days period.\n","\n","    Args:\n","        df (pandas.DataFrame)\n","\n","    Returns:\n","        pd.Series: Return a boolean series indicating if each (id, id_2) pair has incorrect timestamps.\n","    \"\"\"\n","\n","    try:\n","        df['timestamp'] = pd.to_datetime(df['startDay'] + ' ' + df['startTime'], errors='coerce')\n","        df['end_timestamp'] = pd.to_datetime(df['endDay'] + ' ' + df['endTime'], errors='coerce')\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","        print(\"Problematic rows:\")\n","        problematic_rows = df[pd.to_datetime(df['startDay'] + ' ' + df['startTime'], errors='coerce').isnull() |\n","                              pd.to_datetime(df['endDay'] + ' ' + df['endTime'], errors='coerce').isnull()]\n","        print(problematic_rows)\n","        return pd.Series()\n","\n","\n","    time_check_result = (df.groupby(['id', 'id_2'])\n","                         .apply(lambda x: (not x['timestamp'].empty) and\n","                                          (x['timestamp'].min().floor('D') == x['timestamp'].max().floor('D')) and\n","                                          (x['timestamp'].dt.dayofweek.nunique() == 7))\n","                         .reset_index(drop=True))\n","\n","    return time_check_result\n","\n","\n","file_path_2 = '/content/MapUp-Data-Assessment-F/datasets/dataset-2.csv'\n","\n","\n","df = pd.read_csv(file_path_2)\n","\n","print(\"Original DataFrame:\")\n","print(df.head())\n","\n","time_check_result = time_check(df)\n","\n","print(\"\\nTime Check Result:\")\n","print(time_check_result)\n"],"metadata":{"id":"uxcSdzLzgFq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","file_path_3 = '/content/MapUp-Data-Assessment-F/datasets/dataset-3.csv'\n","\n","df = pd.read_csv(file_path_3)\n","\n","df.head()"],"metadata":{"id":"mzxno3wfgfSa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path_t2 = '/content/MapUp-Data-Assessment-F/templates/python_task_2.py'\n","\n","with open(file_path_t2, 'r') as file:\n","    python_code = file.read()\n","\n","print(python_code)"],"metadata":{"id":"jmkSt2xTl-0P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","def calculate_distance_matrix(df):\n","    \"\"\"\n","    Calculate a distance matrix based on the dataframe, df.\n","\n","    Args:\n","        df (pandas.DataFrame)\n","\n","    Returns:\n","        pandas.DataFrame: Distance matrix\n","    \"\"\"\n","\n","    distance_matrix = pd.DataFrame(index=df['id_start'].unique(), columns=df['id_end'].unique())\n","\n","\n","    for index, row in df.iterrows():\n","        # Update the distance matrix with bidirectional distances\n","        distance_matrix.at[row['id_start'], row['id_end']] = row['distance']\n","        distance_matrix.at[row['id_end'], row['id_start']] = row['distance']\n","\n","\n","    distance_matrix.values[[range(distance_matrix.shape[0])]*2] = 0\n","\n","    # Calculate cumulative distances\n","    distance_matrix = distance_matrix.astype(float).groupby(level=0, axis=1).cumsum(axis=1)\n","\n","    return distance_matrix\n","\n","file_path_3 = '/content/MapUp-Data-Assessment-F/datasets/dataset-3.csv'\n","\n","df = pd.read_csv(file_path_3)\n","\n","result_distance_matrix = calculate_distance_matrix(df)\n","\n","print(result_distance_matrix)\n"],"metadata":{"id":"935UXDW5oGit"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","def unroll_distance_matrix(df):\n","    \"\"\"\n","    Unroll a distance matrix to a DataFrame in the style of the initial dataset.\n","\n","    Args:\n","        df (pandas.DataFrame)\n","\n","    Returns:\n","        pandas.DataFrame: Unrolled DataFrame containing columns 'id_start', 'id_end', and 'distance'.\n","    \"\"\"\n","    # Create an empty list to store unrolled data\n","    unrolled_data = []\n","\n","    # Iterate through the rows and columns of the distance matrix\n","    for id_start in df.index:\n","        for id_end in df.columns:\n","            # Exclude diagonal elements\n","            if id_start != id_end:\n","                # Extract the distance value\n","                distance = df.at[id_start, id_end]\n","\n","                # Append data to the unrolled list\n","                unrolled_data.append({'id_start': id_start, 'id_end': id_end, 'distance': distance})\n","\n","    # Create a DataFrame from the unrolled data\n","    unrolled_df = pd.DataFrame(unrolled_data)\n","\n","    return unrolled_df\n","\n","result_distance_matrix = calculate_distance_matrix(df)\n","\n","result_unrolled_df = unroll_distance_matrix(result_distance_matrix)\n","\n","print(result_unrolled_df)\n"],"metadata":{"id":"zxAdEG8ioOhw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","def find_ids_within_ten_percentage_threshold(df, reference_id):\n","    \"\"\"\n","    Find all IDs whose average distance lies within 10% of the average distance of the reference ID.\n","\n","    Args:\n","        df (pandas.DataFrame)\n","        reference_id (int)\n","\n","    Returns:\n","        pandas.DataFrame: DataFrame with IDs whose average distance is within the specified percentage threshold\n","                          of the reference ID's average distance.\n","    \"\"\"\n","\n","    reference_df = df[df['id_start'] == reference_id]\n","\n","    # Calculate the average distance for the reference_id\n","    reference_avg_distance = reference_df['distance'].mean()\n","\n","    # Calculate the percentage threshold\n","    percentage_threshold = 0.10\n","\n","    # Calculate the minimum and maximum acceptable average distances\n","    min_threshold = reference_avg_distance - (reference_avg_distance * percentage_threshold)\n","    max_threshold = reference_avg_distance + (reference_avg_distance * percentage_threshold)\n","\n","    # Filter the DataFrame to include only rows with average distances within the threshold\n","    result_df = df.groupby('id_start')['distance'].mean().reset_index()\n","    result_df = result_df[(result_df['distance'] >= min_threshold) & (result_df['distance'] <= max_threshold)]\n","\n","    # Sort the result DataFrame by average distance in ascending order\n","    result_df = result_df.sort_values(by='distance')\n","\n","    return result_df\n","\n","result_unrolled_df = unroll_distance_matrix(result_distance_matrix)\n","\n","reference_id = 1001400\n","\n","result_filtered_df = find_ids_within_ten_percentage_threshold(result_unrolled_df, reference_id)\n","\n","print(result_filtered_df)\n"],"metadata":{"id":"YUQs7KIkor9t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","def calculate_toll_rate(df):\n","    \"\"\"\n","    Calculate toll rates for each vehicle type based on the unrolled DataFrame.\n","\n","    Args:\n","        df (pandas.DataFrame)\n","\n","    Returns:\n","        pandas.DataFrame\n","    \"\"\"\n","\n","    rate_coefficients = {'moto': 0.8, 'car': 1.2, 'rv': 1.5, 'bus': 2.2, 'truck': 3.6}\n","\n","\n","    for vehicle_type, rate_coefficient in rate_coefficients.items():\n","        # Create a new column for each vehicle type with calculated toll rates\n","        df[vehicle_type] = df['distance'] * rate_coefficient\n","\n","    return df\n","\n","result_unrolled_df = unroll_distance_matrix(result_distance_matrix)\n","\n","result_with_toll_rates = calculate_toll_rate(result_unrolled_df)\n","\n","print(result_with_toll_rates)"],"metadata":{"id":"GlJppHIb9iSm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from datetime import time\n","\n","def calculate_time_based_toll_rates(df):\n","    \"\"\"\n","    Calculate time-based toll rates for different time intervals within a day.\n","\n","    Args:\n","        df (pandas.DataFrame)\n","\n","    Returns:\n","        pandas.DataFrame\n","    \"\"\"\n","\n","    discount_factors = {\n","        'weekday_morning': 0.8,\n","        'weekday_daytime': 1.2,\n","        'weekday_evening': 0.8,\n","        'weekend': 0.7\n","    }\n","\n","    # Define time ranges\n","    time_ranges = {\n","        'morning': (time(0, 0), time(10, 0)),\n","        'daytime': (time(10, 0), time(18, 0)),\n","        'evening': (time(18, 0), time(23, 59, 59))\n","    }\n","\n","\n","    df['start_day'] = 'Monday'\n","    df['start_time'] = time(0, 0)\n","    df['end_day'] = 'Sunday'\n","    df['end_time'] = time(23, 59, 59)\n","\n","\n","    for index, row in df.iterrows():\n","        for vehicle_type in ['moto', 'car', 'rv', 'bus', 'truck']:\n","            if row['start_day'] in ['Saturday', 'Sunday']:\n","                df.at[index, vehicle_type] *= discount_factors['weekend']\n","            else:\n","                for time_range, (start, end) in time_ranges.items():\n","                    if start <= row['start_time'] < end:\n","                        df.at[index, vehicle_type] *= discount_factors[f'weekday_{time_range}']\n","                        break\n","\n","    return df\n","\n","final_df = calculate_time_based_toll_rates(result_with_toll_rates)\n","\n","print(final_df)\n"],"metadata":{"id":"IeI9gdQnAYu0"},"execution_count":null,"outputs":[]}]}